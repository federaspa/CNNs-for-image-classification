{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/federaspa/CNNs-for-image-classification/blob/main/CNN_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNNs for Image Classification with Pytorch\n",
        "For more details about the notebook, check out the Readme file."
      ],
      "metadata": {
        "id": "TxcE3uy7qztf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsEepa-stdY1"
      },
      "outputs": [],
      "source": [
        "! pip install --quiet \"setuptools==59.5.0\" \"ipython[notebook]\" \"torchmetrics>=0.7\" \"torchvision\" \"seaborn\" \"torchviz\" \"pytorch-lightning\"\n",
        "! rm -rf ./logs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68uwyRRi4BMK"
      },
      "outputs": [],
      "source": [
        "# Import all the livraries needed for the first two parts. Find details in the Readme\n",
        "\n",
        "from IPython.display import Image\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torch.utils.tensorboard.writer import SummaryWriter\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Normalize, Compose\n",
        "\n",
        "from torchmetrics.classification import MulticlassAccuracy\n",
        "\n",
        "from torchviz import make_dot\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "from pytorch_lightning.utilities.model_summary.model_summary import ModelSummary\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import datetime\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Content was provided on Google Drive, therefore we mount the directory on CoLab\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "# We initialize tensorboard's SummaryWriter to log our models' progression\n",
        "writer = SummaryWriter()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If available, we use cuda\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "id": "bjU98dX87GQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training functions\n",
        "\n",
        "As we use the same training and validation functions for all the models in the notebook, we define them immediately"
      ],
      "metadata": {
        "id": "5ME2b4bdrObG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LrLephVqxWK"
      },
      "outputs": [],
      "source": [
        "# The training function\n",
        "def train(dataloader, model, metric, loss_fn, optimizer, epoch, device):\n",
        "    outputs_list = []\n",
        "\n",
        "    # Iterate over all batches. pbar:= allows us to display our training's progression with a progress bar.\n",
        "    for batch, (X, y) in (pbar:= tqdm(enumerate(dataloader), total=len(dataloader))):\n",
        "        # Need to convert X and y dtype to implement VGG16 later\n",
        "        X = X.to(device).float()\n",
        "        y = y.to(device).long()\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Add batch lostt to tensorboard's writer\n",
        "        writer.add_scalar(\"Loss/train\", loss, batch)\n",
        "\n",
        "        # Collect batch metrics in a list\n",
        "        outputs_list.append({\"loss\": loss, \"preds\": pred, \"labels\": y})\n",
        "\n",
        "        # Update progress bar\n",
        "        pbar.set_description(desc=f\"Train - Loss:{loss:.2f}\")\n",
        "\n",
        "    # Join batch metrics and compute accuracy\n",
        "    preds = torch.cat([x[\"preds\"] for x in outputs_list]).detach().cpu()\n",
        "    labels = torch.cat([x[\"labels\"] for x in outputs_list]).detach().cpu()\n",
        "    loss = torch.stack([x[\"loss\"] for x in outputs_list]).mean()\n",
        "    acc = metric(preds, labels)\n",
        "    \n",
        "    # Log everything to tensorboard's writer\n",
        "    writer.add_scalar(f\"train/loss\", loss, epoch)\n",
        "    writer.add_scalar(f\"train/acc\", acc, epoch)\n",
        "\n",
        "    print(f\"Train - Loss: {loss:.2f}, Acc: {acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "891DeX-QrAJx"
      },
      "outputs": [],
      "source": [
        "# Validation and test function, depending on the \"validation\" parameter. The only differences are that this does not log\n",
        "# the batch parameters and returns something.\n",
        "# If the function is used as a test function, it also returns the predictions, otherwise only the accuracy\n",
        "\n",
        "def test(dataloader, model, metric, loss_fn, epoch, device, validation = True):\n",
        "    outputs_list = []\n",
        "\n",
        "    # We freeze the gradients at evaluation\n",
        "    with torch.no_grad():\n",
        "        for batch, (X, y) in (pbar:= tqdm(enumerate(dataloader), total=len(dataloader))):\n",
        "            X = X.to(device).float()\n",
        "            y = y.to(device).long()\n",
        "            pred = model(X)\n",
        "            test_loss = loss_fn(pred, y)\n",
        "            \n",
        "            outputs_list.append({\"loss\": test_loss, \"preds\": pred, \"labels\": y})\n",
        "            pbar.set_description(desc=f\"Val - Loss:{test_loss:.2f}\")\n",
        "\n",
        "    preds = torch.cat([x[\"preds\"] for x in outputs_list]).detach().cpu()\n",
        "    labels = torch.cat([x[\"labels\"] for x in outputs_list]).detach().cpu()\n",
        "    loss = torch.stack([x[\"loss\"] for x in outputs_list]).mean()\n",
        "    acc = metric(preds, labels)\n",
        "    \n",
        "    if validation:\n",
        "        writer.add_scalar(f\"val/loss\", loss, epoch)\n",
        "        writer.add_scalar(f\"val/acc\", acc, epoch)    \n",
        "\n",
        "    print(f\"Val - Loss: {loss:.2f}, Acc: {acc}\")\n",
        "    \n",
        "    # We return the accuracy to implement the Callback\n",
        "    if validation:\n",
        "        result = acc\n",
        "    else:\n",
        "        result = (acc, preds)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_dataloader, val_dataloader, optimizer, epochs = 20, patience = 5, delta = 1e-4):\n",
        "    for t in range(epochs):\n",
        "        counter, best_acc = 0,0\n",
        "        print(f\"-------------------------------\\nEpoch {t+1}\\n-------------------------------\")\n",
        "\n",
        "        model.train()\n",
        "        train(train_dataloader, model, metric, loss_fn, optimizer, t, device)\n",
        "        \n",
        "        model.eval()\n",
        "        val_acc = test(val_dataloader, model, metric, loss_fn, t, device)\n",
        "\n",
        "        # EarlyStopping: if the model does not improve significantly after some eopchs, stop training to prevent overfitting\n",
        "        if (val_acc > best_acc and val_acc-best_acc >= delta):\n",
        "            best_acc = val_acc\n",
        "            counter = 0\n",
        "        elif (val_acc > best_acc and val_acc-best_acc < delta):\n",
        "            best_acc = val_acc\n",
        "            counter += 1\n",
        "        else:\n",
        "            counter +=1\n",
        "\n",
        "        if counter >= patience:\n",
        "            print(f\"No significant improvement after {patience} epochs, stopping early.\")\n",
        "            break\n",
        "\n",
        "    print(\"Done!\")\n",
        "    writer.flush()"
      ],
      "metadata": {
        "id": "ZIK3TPVcaZp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfp1U9PMeQU1"
      },
      "source": [
        "# I. First step: Simple Convolutional Neural Network\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reg9BJqwTVYm"
      },
      "source": [
        "### Collecting and loading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmRN-h2UFtTt"
      },
      "outputs": [],
      "source": [
        "# Download training data from open datasets\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform = Compose([\n",
        "    ToTensor()])\n",
        ")\n",
        "\n",
        "# Download test data from open datasets\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=Compose([\n",
        "    ToTensor()])\n",
        ")\n",
        "\n",
        "# Display information about the data\n",
        "print( 'Train data: ', training_data)\n",
        "print( 'Test data: ', test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-V3QYHkYHNKY"
      },
      "outputs": [],
      "source": [
        "# Split training data into test and validation set\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(training_data, [0.8,0.2])\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 128\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size,shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "# Check our data's dimensions\n",
        "for X, y in train_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.size()}\")\n",
        "    print(f\"Shape of y: {y.size()}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring the data"
      ],
      "metadata": {
        "id": "wsjtt0hdrCgQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSxBMFiCCZ4B"
      },
      "outputs": [],
      "source": [
        "# Display a few datapoints and the corresponding labels\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(label)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building and training the model with Pytorch"
      ],
      "metadata": {
        "id": "xENaATaJrUpU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Architecture"
      ],
      "metadata": {
        "id": "SucpMAShrI5U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxdOWPUBhAAH"
      },
      "outputs": [],
      "source": [
        "# Our class extends the nn.Module class. \n",
        "# We will be using this module again for the next dataset, therefore we make the input_channels and num_classes user-defined.\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self, num_classes, input_channels):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # Feature extraction stack\n",
        "        self.conv_stack = nn.Sequential(\n",
        "            nn.Conv2d(input_channels,6,(5,5),padding=2),\n",
        "            nn.Sigmoid(),\n",
        "            nn.AvgPool2d((2,2),stride=2),\n",
        "            nn.Conv2d(6,16,(5,5)),\n",
        "            nn.Sigmoid(),\n",
        "            nn.AvgPool2d((2,2),stride=2),\n",
        "        )\n",
        "\n",
        "        # Classification stack\n",
        "        self.dense_stack = nn.Sequential(\n",
        "            nn.LazyLinear(120),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(120,84),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(84,num_classes),\n",
        "            nn.Softmax()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_stack(x)\n",
        "        x = self.flatten(x)\n",
        "        logits = self.dense_stack(x)\n",
        "\n",
        "        return logits\n",
        "\n",
        "model = LeNet(10, 1)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us plot the model's graph and each layer's shapes\n",
        "# The torchviz library requires us to pass a dummy batch to the model's forward()\n",
        "batch = next(iter(train_dataloader))\n",
        "yhat = model(batch[0])\n",
        "\n",
        "make_dot(yhat, params=dict(list(model.named_parameters()))).render(\"model_torchviz\", format=\"png\")"
      ],
      "metadata": {
        "id": "Aa9Yh74xN3Xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display information about our model's layers\n",
        "summary(model.to(device), (1,28,28))"
      ],
      "metadata": {
        "id": "8EDY7R3vQqs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "0XUaGXoYvIMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "input_channels = 1\n",
        "\n",
        "metric = MulticlassAccuracy(num_classes)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "model = LeNet(num_classes, input_channels).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "train_model(model, train_dataloader, val_dataloader, optimizer)"
      ],
      "metadata": {
        "id": "-cpjamvobEQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results"
      ],
      "metadata": {
        "id": "2D0QgGHEGEbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir=runs"
      ],
      "metadata": {
        "id": "U8S3ZIMJGGfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "acc,_ = test(val_dataloader, model, metric, loss_fn, 0, device, validation = False)\n",
        "\n",
        "print(\"Accuracy on test set: {0}\".format(acc))"
      ],
      "metadata": {
        "id": "if6q1bBpxaBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building and training the model with Pytorch Lighting"
      ],
      "metadata": {
        "id": "VXX9GEjBrDsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LitAutoLeNet(pl.LightningModule):\n",
        "    def __init__(self, num_classes, input_channels, loss, metric):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.conv_stack = nn.Sequential(\n",
        "            nn.Conv2d(input_channels,6,(5,5),padding=2),\n",
        "            nn.Sigmoid(),\n",
        "            nn.AvgPool2d((2,2),stride=2),\n",
        "            nn.Conv2d(6,16,(5,5)),\n",
        "            nn.Sigmoid(),\n",
        "            nn.AvgPool2d((2,2),stride=2),\n",
        "        )\n",
        "        self.dense_stack = nn.Sequential(\n",
        "            nn.LazyLinear(120),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(120,84),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(84,num_classes),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "        self.loss_fn = loss\n",
        "        self.metric_fn = metric\n",
        "\n",
        "    def training_step(self, train_batch, batch_idx):\n",
        "        # training_step defines the train loop.\n",
        "        # it is independent of forward\n",
        "        x, y = train_batch\n",
        "        pred = self.conv_stack(x)\n",
        "        pred = self.flatten(pred)\n",
        "        pred = self.dense_stack(pred)\n",
        "\n",
        "        loss = self.loss_fn(pred, y)\n",
        "        acc = self.metric_fn(pred.argmax(1), y)\n",
        "        \n",
        "        # Logging to TensorBoard\n",
        "        values = {\"train_loss\": loss, \"train_acc\": acc}\n",
        "        self.log_dict(values, on_epoch = True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, val_batch, batch_idx):\n",
        "        # validation_step defines the validation loop.\n",
        "        x, y = val_batch\n",
        "\n",
        "        pred = self.conv_stack(x)\n",
        "        pred = self.flatten(pred)\n",
        "        pred = self.dense_stack(pred)\n",
        "\n",
        "        loss = self.loss_fn(pred, y)\n",
        "        acc = self.metric_fn(pred.argmax(1), y)\n",
        "\n",
        "        values = {\"val_loss\": loss, \"val_acc\": acc}\n",
        "        self.log_dict(values, on_epoch = True, prog_bar = True)\n",
        "\n",
        "    def test_step(self, test_batch, batch_idx):\n",
        "        # test_step defines the test loop. \n",
        "        x, y = test_batch\n",
        "\n",
        "        pred = self.conv_stack(x)\n",
        "        pred = self.flatten(pred)\n",
        "        pred = self.dense_stack(pred)\n",
        "\n",
        "        loss = self.loss_fn(pred, y)\n",
        "        acc = self.metric_fn(pred.argmax(1), y)\n",
        "\n",
        "        self.log(\"test_acc\", acc)\n",
        "\n",
        "        return acc\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters())\n",
        "        return optimizer"
      ],
      "metadata": {
        "id": "IWInjP8roqKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define metric and loss function\n",
        "input_channels = 1\n",
        "num_classes = 10\n",
        "metric = MulticlassAccuracy(num_classes)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Initialize the model\n",
        "model = LitAutoLeNet(num_classes, input_channels, loss_fn, metric)\n",
        "\n",
        "# Wrap the model in a trainer object and instantiate an early stopping \n",
        "early_stopping = EarlyStopping('val_loss')\n",
        "trainer = pl.Trainer(gpus=1, callbacks=[early_stopping], max_epochs=20)"
      ],
      "metadata": {
        "id": "9iWRlJROu2qT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(model, train_dataloader, val_dataloader)"
      ],
      "metadata": {
        "id": "_yv3uGXupMyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results"
      ],
      "metadata": {
        "id": "CaPi-Z3DrZfW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PS6aDuthV85A"
      },
      "outputs": [],
      "source": [
        "#Plot the curve of the metrics during training\n",
        "%tensorboard --logdir=lightning_logs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(ckpt_path=\"best\", dataloaders=test_dataloader)"
      ],
      "metadata": {
        "id": "ZRsNsDu0tliY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jEoZxb2l--M"
      },
      "source": [
        "# II. Second step: Simple Convolutionnal Neural Network on more complex data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbGIVZForf3r"
      },
      "source": [
        "### Collecting and loading the data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to create a custom dataset that extends the Dataset class\n",
        "class MedMNISTDataset(Dataset):\n",
        "    def __init__(self, label_array, img_array, transform=None, target_transform=None):\n",
        "\n",
        "        # Load the npy arrays where our data is stored\n",
        "        self.img_labels = np.load(label_array)\n",
        "        self.img_array = np.load(img_array)\n",
        "\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        # Pair each image with its label and apply transformations\n",
        "        image = self.img_array[idx]\n",
        "        label = self.img_labels[idx, 0]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "gm1cJqtCqX80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ULAOQzgWtXi"
      },
      "outputs": [],
      "source": [
        "# preprocessing\n",
        "data_transform = Compose([\n",
        "    ToTensor(),\n",
        "])\n",
        "\n",
        "# load the data\n",
        "xTrain='/content/drive/MyDrive/Colab Notebooks/Computer Vision/Lab3/pathmnist/train_images.npy'\n",
        "xVal='/content/drive/MyDrive/Colab Notebooks/Computer Vision/Lab3/pathmnist/val_images.npy'\n",
        "xTest='/content/drive/MyDrive/Colab Notebooks/Computer Vision/Lab3/pathmnist/test_images.npy'\n",
        "\n",
        "yTrain='/content/drive/MyDrive/Colab Notebooks/Computer Vision/Lab3/pathmnist/train_labels.npy'\n",
        "yVal='/content/drive/MyDrive/Colab Notebooks/Computer Vision/Lab3/pathmnist/val_labels.npy'\n",
        "yTest='/content/drive/MyDrive/Colab Notebooks/Computer Vision/Lab3/pathmnist/test_labels.npy'\n",
        "\n",
        "\n",
        "# Wrap the data into datasets\n",
        "train_dataset = MedMNISTDataset(yTrain,xTrain, data_transform)\n",
        "val_dataset = MedMNISTDataset(yVal,xVal, data_transform)\n",
        "test_dataset = MedMNISTDataset(yTest,xTest, data_transform)\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "# Wrap datasets into dataloaders\n",
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring the data"
      ],
      "metadata": {
        "id": "OgvLa96ZrmMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a few datapoints\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
        "    img, label = train_dataset[sample_idx]\n",
        "    img = img.permute(1, 2, 0)\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(label)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LhLEMesNGjMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building and training the model with Pytorch"
      ],
      "metadata": {
        "id": "itQRJK-PrtMj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Architecture"
      ],
      "metadata": {
        "id": "FGz-vfFYrvzR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu-u-l_EUtA_"
      },
      "outputs": [],
      "source": [
        "# We use the same architecture that we used for MNIST, we only change the number of classes to 9 and the input channels to 3, \n",
        "# as we are now working with RGB data\n",
        "model_med = LeNet(9, 3)\n",
        "print(model_med)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMrrzEQCS3CV"
      },
      "outputs": [],
      "source": [
        "batch = next(iter(train_dataloader))\n",
        "yhat = model_med(batch[0])\n",
        "\n",
        "make_dot(yhat, params=dict(list(model_med.named_parameters()))).render(\"model_med_torchviz\", format=\"png\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model_med.to(device), (3,28,28))"
      ],
      "metadata": {
        "id": "wIVDoghFenq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "QeD-YJwWr0Bc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUlN501raXPT"
      },
      "outputs": [],
      "source": [
        "num_classes = 9\n",
        "input_channels = 3\n",
        "\n",
        "metric = MulticlassAccuracy(num_classes)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "model_med = LeNet(num_classes, input_channels).to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model_med.parameters())\n",
        "\n",
        "train_model(model_med, train_dataloader, val_dataloader, optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results"
      ],
      "metadata": {
        "id": "2i2f0cy9r5Rg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbbIaupMaXPV"
      },
      "outputs": [],
      "source": [
        "#Plot the curve of the metrics during training\n",
        "%tensorboard --logdir=runs "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_med.eval()\n",
        "acc = test(test_dataloader, model_med, metric, loss_fn, 0, device, validation = False)\n",
        "\n",
        "print(\"Accuracy on test set: {0}\".format(acc))"
      ],
      "metadata": {
        "id": "yoFzSETz1hey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building and training the model with Pytorch Lightning"
      ],
      "metadata": {
        "id": "L6wtKxjqyCJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define metric and loss function\n",
        "num_classes = 9\n",
        "input_channels = 3\n",
        "\n",
        "metric = MulticlassAccuracy(num_classes)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Initialize the model\n",
        "model = LitAutoLeNet(num_classes,input_channels, loss_fn, metric)\n",
        "\n",
        "# Wrap the model in a trainer object and instantiate an early stopping \n",
        "early_stopping = EarlyStopping('val_loss')\n",
        "trainer = pl.Trainer(gpus=1, callbacks=[early_stopping], max_epochs=20)"
      ],
      "metadata": {
        "id": "Rjjy3E0Nz4_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(model, train_dataloader, val_dataloader)"
      ],
      "metadata": {
        "id": "ajn99SqXz4_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results"
      ],
      "metadata": {
        "id": "kxVlfCgEz4_L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tyJUzcIz4_M"
      },
      "outputs": [],
      "source": [
        "#Plot the curve of the metrics during training\n",
        "%tensorboard --logdir=lightning_logs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(ckpt_path=\"best\", dataloaders=test_dataloader)"
      ],
      "metadata": {
        "id": "7QF8pgBoz4_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzyPbiXU8m2Y"
      },
      "source": [
        "# III. Third step: Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We import the vgg16 model, its default weights and the PIL Library.\n",
        "# We also initialize the defaul weights and the preprocessing of the images\n",
        "\n",
        "from torchvision.models import vgg16, VGG16_Weights\n",
        "weights=VGG16_Weights.DEFAULT\n",
        "preprocess = weights.transforms()\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import glob"
      ],
      "metadata": {
        "id": "39LR2dQhAkg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WxbuhZQsBZv"
      },
      "source": [
        "### Collecting and loading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkVd3v4N3LnB"
      },
      "outputs": [],
      "source": [
        "def load_images(root, classes, shuffle = True, train = True, num_images = None):\n",
        "    classLabel = 0\n",
        "\n",
        "    xArray = torch.empty(size=(0,3,224,224))\n",
        "    yArray = []\n",
        "    first = True\n",
        "    for cl in tqdm(classes):\n",
        "        listImages = glob.glob(root+cl+'/*')\n",
        "        if not train:\n",
        "            num_images = len(listImages)\n",
        "        yArray += [classLabel]*num_images\n",
        "        for pathImg in tqdm(listImages[:num_images]):\n",
        "            img = Image.open(pathImg)\n",
        "            im = preprocess(img)\n",
        "            im = torch.unsqueeze(im, dim=0)\n",
        "            xArray = torch.vstack((xArray, im))\n",
        "        classLabel += 1\n",
        "\n",
        "    return xArray, yArray"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the local folder where the ANIMAL10 images are stored\n",
        "datasetRoot='/content/drive/MyDrive/Colab Notebooks/Computer Vision/Lab3/animal-10/raw-img/'\n",
        "\n",
        "# define the classes we want to model\n",
        "classes = ['mucca', 'gatto']\n",
        "nbClasses = len(classes)\n",
        "\n",
        "rootTrain = datasetRoot+'train/'\n",
        "rootTest = datasetRoot+'test/'"
      ],
      "metadata": {
        "id": "D00iNVi6fY4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xTrain, yTrain = load_images(rootTrain, classes, num_images = 500)\n",
        "xTest, yTest = load_images(rootTest, classes, shuffle = False, train = False)"
      ],
      "metadata": {
        "id": "PAi289x-ghVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AnimalDataset(Dataset):\n",
        "    def __init__(self, label_array, img_array):\n",
        "        self.img_labels = label_array\n",
        "        self.img_array = img_array\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.img_array[idx]\n",
        "        label = torch.tensor(self.img_labels[idx])\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "p8iVfMt2VMsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_val_dataset = AnimalDataset(yTrain,xTrain)\n",
        "test_dataset = AnimalDataset(yTest, xTest)\n",
        "\n",
        "train_dataset, val_dataset = random_split(train_val_dataset, [0.8, 0.2])\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "2p9jVaGRWAcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring the data"
      ],
      "metadata": {
        "id": "oeaPQjDgsF9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a few datapoints\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    img, label = xTrain[i-1], yTrain[i-1]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(label)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow((img *255).permute(1,2,0).to(torch.uint8))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JB6GLcWqIUFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og1KZntwavZT"
      },
      "source": [
        "## Pre-trained model with Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Architecture"
      ],
      "metadata": {
        "id": "X-BevdBesmAi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofrQr-x_a-Bi"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained VGG16 model\n",
        "vgg16_model = vgg16(weights = VGG16_Weights.DEFAULT)\n",
        "\n",
        "# Customize pooling and classifier layers of the model\n",
        "# vgg16_model.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "\n",
        "vgg16_model.classifier = nn.Sequential(\n",
        "    nn.Linear(in_features=512*7*7, out_features=1024),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(in_features=1024, out_features=2),\n",
        "    nn.Softmax(dim = 1),\n",
        "  )\n",
        "\n",
        "# Freeze all layers except for the classifier's\n",
        "for param in iter(vgg16_model.features.parameters()):\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in iter(vgg16_model.classifier.parameters()):\n",
        "    param.requires_grad = True\n",
        "\n",
        "print(vgg16_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(vgg16_model.to(device), (3,224,224))"
      ],
      "metadata": {
        "id": "tiDiMWkCd5tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PuXNGD-KUvl"
      },
      "outputs": [],
      "source": [
        "## Let us plot the model's graph and each layer's shapes\n",
        "batch = list(train_dataloader)[0]\n",
        "yhat = vgg16_model(batch[0].to(device))\n",
        "\n",
        "make_dot(yhat, params=dict(list(vgg16_model.named_parameters()))).render(\"model_animal_torchviz\", format=\"png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "gahlXWIIsq-C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrLUhA2-b8Fv"
      },
      "outputs": [],
      "source": [
        "metric = MulticlassAccuracy(num_classes=2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "model = vgg16_model.to(device)\n",
        "\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr = 1e-2)\n",
        "\n",
        "train_model(model, train_dataloader, val_dataloader, optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results"
      ],
      "metadata": {
        "id": "n8aVCOulFrim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir=runs"
      ],
      "metadata": {
        "id": "iidELJ7UFtmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix:\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "vgg16_model.eval()\n",
        "acc, preds = test(test_dataloader, vgg16_model, metric, loss_fn, 0, device, validation = False)\n",
        "\n",
        "y_classes = preds.argmax(axis=-1)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_true = yTest, y_pred = y_classes)\n",
        "\n",
        "df_cm = pd.DataFrame(cm)\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm, annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I26g2JTHq0Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-trained model with Pytorch Lightning"
      ],
      "metadata": {
        "id": "bIuaKMqLPMhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AnimalsClassifier(pl.LightningModule):\n",
        "    def __init__(self, loss_fn, metric_fn):\n",
        "        super().__init__()\n",
        "        # init the pretrained LightningModule\n",
        "        self.feature_extractor =  vgg16(weights=\"DEFAULT\").features\n",
        "\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=512*7*7, out_features=1024, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=1024, out_features=2, bias=True),\n",
        "            nn.Softmax(dim=1),\n",
        "        )\n",
        "\n",
        "        for param in iter(self.feature_extractor.parameters()):\n",
        "            param.requires_grad = False\n",
        "\n",
        "        for param in iter(self.classifier.parameters()):\n",
        "            param.requires_grad = True\n",
        "\n",
        "        self.loss_fn = loss_fn\n",
        "        self.metric_fn = metric_fn\n",
        "\n",
        "    def forward(self, x):\n",
        "        representations = self.feature_extractor(x)\n",
        "        x = self.global_pool(representations)\n",
        "        x = torch.flatten(x, 1)\n",
        "        logits = self.classifier(x)\n",
        "        return logits\n",
        "\n",
        "    def training_step(self, train_batch, batch_idx):\n",
        "        # training_step defines the train loop.\n",
        "        # it is independent of forward\n",
        "        x, y = train_batch\n",
        "        y=y.to(self.device, dtype=torch.long)\n",
        "\n",
        "\n",
        "        pred = self.feature_extractor(x)\n",
        "        pred = self.global_pool(pred)\n",
        "        preds = self.classifier(pred)\n",
        "\n",
        "        loss = self.loss_fn(preds, y)\n",
        "        acc = self.metric_fn(preds, y)\n",
        "        \n",
        "        # Logging to TensorBoard (if installed) by default\n",
        "        values = {\"train_loss\": loss, \"train_acc\": acc}\n",
        "        self.log_dict(values, on_epoch = True)\n",
        "        \n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, val_batch, batch_idx):\n",
        "        x, y = val_batch\n",
        "        y=y.to(self.device, dtype=torch.long)\n",
        "\n",
        "        pred = self.feature_extractor(x)\n",
        "        pred = self.global_pool(pred)\n",
        "        preds = self.classifier(pred)\n",
        "\n",
        "        loss = self.loss_fn(preds, y)\n",
        "        acc = self.metric_fn(preds, y)\n",
        "\n",
        "        values = {\"val_loss\": loss, \"val_acc\": acc}\n",
        "        self.log_dict(values, on_epoch = True, prog_bar = True)\n",
        "\n",
        "    def test_step(self, test_batch, batch_idx):\n",
        "        x, y = test_batch\n",
        "        y=y.to(self.device, dtype=torch.long)\n",
        "\n",
        "\n",
        "        pred = self.feature_extractor(x)\n",
        "        pred = self.global_pool(pred)\n",
        "        preds = self.classifier(pred)\n",
        "\n",
        "        loss = self.loss_fn(preds, y)\n",
        "        acc = self.metric_fn(preds, y)\n",
        "\n",
        "        self.log(\"test_acc\", acc)\n",
        "\n",
        "        return acc\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.RMSprop(self.parameters(), lr=1e-2)\n",
        "        return optimizer"
      ],
      "metadata": {
        "id": "nSN53GLhPS4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = MulticlassAccuracy(num_classes=2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "model = AnimalsClassifier(loss_fn, metric)\n",
        "\n",
        "early_stopping = EarlyStopping('val_loss')\n",
        "trainer = pl.Trainer(\n",
        "    gpus=1, \n",
        "    callbacks=[early_stopping], \n",
        "    max_epochs=50)"
      ],
      "metadata": {
        "id": "XQXqBHi6PdzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for child in iter(model.feature_extractor.children()):\n",
        "    for param in iter(child.parameters()):\n",
        "        param.requires_grad=False"
      ],
      "metadata": {
        "id": "kbKk7xOMDmh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ModelSummary(model,max_depth=-1) "
      ],
      "metadata": {
        "id": "OdNUv3xsCQXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(model, train_dataloader, val_dataloader)"
      ],
      "metadata": {
        "id": "G324OYzgPdzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results"
      ],
      "metadata": {
        "id": "J1z-_oM1PdzZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNnErv4qPdza"
      },
      "outputs": [],
      "source": [
        "#Plot the curve of the metrics during training\n",
        "%tensorboard --logdir=lightning_logs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(ckpt_path=\"best\", dataloaders=test_dataloader)"
      ],
      "metadata": {
        "id": "2PLISkGmPdza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hgDguiNcNXZ"
      },
      "source": [
        "## Fine-tune the network with Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Architecture"
      ],
      "metadata": {
        "id": "uX_5zY6htfsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-load pre-trained VGG16 model\n",
        "vgg16_model = vgg16(weights = VGG16_Weights.DEFAULT)\n",
        "\n",
        "vgg16_model.classifier = nn.Sequential(\n",
        "    nn.Linear(in_features=512*7*7, out_features=1024),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(in_features=1024, out_features=2),\n",
        "    nn.Softmax(dim = 1),\n",
        "  )\n",
        "\n",
        "# Freeze all layers except for the classifier's\n",
        "for param in iter(vgg16_model.features.parameters()):\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in iter(vgg16_model.classifier.parameters()):\n",
        "    param.requires_grad = True\n",
        "\n",
        "print(vgg16_model)"
      ],
      "metadata": {
        "id": "SY9iUUX7sxt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us check all the named parameters in the model's feature extractor. We notice that the last two\n",
        "# parameters correspond to the model's 28th layer, which is the last convolution.\n",
        "i=0\n",
        "for name, param in vgg16_model.features.named_parameters():\n",
        "    i+=1\n",
        "    print(i,name)"
      ],
      "metadata": {
        "id": "VCLOyPNx_Y43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C17ts6kllGUr"
      },
      "outputs": [],
      "source": [
        "# Unfreeze all layers starting from the last convolutional layer\n",
        "\n",
        "for param in list(vgg16_model.features.named_parameters())[-2:]:\n",
        "    param[1].requires_grad = True"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "9HqOMqTbti8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We use a smaller learning rate to fine-tune the model. \n",
        "\n",
        "metric = MulticlassAccuracy(num_classes=2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "model = vgg16_model.to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters())\n",
        "\n",
        "train_model(model, train_dataloader, val_dataloader, optimizer)"
      ],
      "metadata": {
        "id": "TfSCzVFRAnQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results"
      ],
      "metadata": {
        "id": "NXc18CVCszzd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNI7pEEo0B5F"
      },
      "outputs": [],
      "source": [
        "#TO DO: Plot the curves of the metrics\n",
        "%tensorboard --logdir=runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L30MfqXQx46l"
      },
      "outputs": [],
      "source": [
        "# Let us compute the confusion matrix\n",
        "model.eval()\n",
        "acc, preds = test(test_dataloader, vgg16_model, metric, loss_fn, 0, device, validation = False)\n",
        "\n",
        "y_classes = preds.argmax(axis=-1)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_true = yTest, y_pred = y_classes)\n",
        "\n",
        "df_cm = pd.DataFrame(cm)\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm, annot=True)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "n8aVCOulFrim",
        "J1z-_oM1PdzZ",
        "xU2vDNH0ErkJ",
        "cG1NW0zBFcHC"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}