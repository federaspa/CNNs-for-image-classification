{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CNNs for Image Classifocation with Pytorch"
      ],
      "metadata": {
        "id": "TxcE3uy7qztf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsEepa-stdY1"
      },
      "outputs": [],
      "source": [
        "! pip install --quiet \"setuptools==59.5.0\" \"ipython[notebook]\" \"torchmetrics>=0.7\" \"torchvision\" \"seaborn\" \"torchviz\"\n",
        "! rm -rf ./logs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68uwyRRi4BMK"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Normalize, Compose\n",
        "from torchmetrics.classification import MulticlassAccuracy\n",
        "from torchviz import make_dot\n",
        "from torchsummary import summary\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import datetime\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "writer = SummaryWriter()\n",
        "\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfp1U9PMeQU1"
      },
      "source": [
        "# I. First step: Simple Convolutional Neural Network\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reg9BJqwTVYm"
      },
      "source": [
        "### Collecting and loading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmRN-h2UFtTt"
      },
      "outputs": [],
      "source": [
        "# Download training data from open datasets\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform = Compose([\n",
        "    ToTensor()])\n",
        ")\n",
        "\n",
        "# Download test data from open datasets\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=Compose([\n",
        "    ToTensor()])\n",
        ")\n",
        "\n",
        "# Display information about the data\n",
        "print( 'Train data: ', training_data)\n",
        "print( 'Test data: ', test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-V3QYHkYHNKY"
      },
      "outputs": [],
      "source": [
        "# Split training data into test and validation set\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(training_data, [0.8,0.2])\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "# Check our data's dimensions\n",
        "for X, y in train_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.size()}\")\n",
        "    print(f\"Shape of y: {y.size()}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring the data"
      ],
      "metadata": {
        "id": "wsjtt0hdrCgQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSxBMFiCCZ4B"
      },
      "outputs": [],
      "source": [
        "# Display a few datapoints\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(label)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building and training the model"
      ],
      "metadata": {
        "id": "xENaATaJrUpU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Architecture"
      ],
      "metadata": {
        "id": "SucpMAShrI5U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxdOWPUBhAAH"
      },
      "outputs": [],
      "source": [
        "# Our class extends the nn.Module class\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # Feature extraction stack\n",
        "        self.conv_stack = nn.Sequential(\n",
        "            nn.Conv2d(1,6,(5,5),padding=2),\n",
        "            nn.Sigmoid(),\n",
        "            nn.AvgPool2d((2,2),stride=2),\n",
        "            nn.Conv2d(6,16,(5,5)),\n",
        "            nn.Sigmoid(),\n",
        "            nn.AvgPool2d((2,2),stride=2),\n",
        "        )\n",
        "\n",
        "        # Classification stack\n",
        "        self.dense_stack = nn.Sequential(\n",
        "            nn.LazyLinear(120),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(120,84),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(84,10),\n",
        "            nn.Softmax()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_stack(x)\n",
        "        x = self.flatten(x)\n",
        "        logits = self.dense_stack(x)\n",
        "\n",
        "        return logits\n",
        "\n",
        "model = LeNet()\n",
        "\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us plot the model's graph and each layer's shapes\n",
        "# The torchviz library requires us to pass a dummy batch to the model's forward()\n",
        "batch = next(iter(train_dataloader))\n",
        "yhat = model(batch[0])\n",
        "\n",
        "make_dot(yhat, params=dict(list(model.named_parameters()))).render(\"model_torchviz\", format=\"png\")"
      ],
      "metadata": {
        "id": "Aa9Yh74xN3Xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display information about our model's layers\n",
        "summary(model.to(device), (1,28,28))"
      ],
      "metadata": {
        "id": "8EDY7R3vQqs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "5ME2b4bdrObG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LrLephVqxWK"
      },
      "outputs": [],
      "source": [
        "# Create the training function\n",
        "def train(dataloader, model, metric, loss_fn, optimizer, epoch, device):\n",
        "    size = len(dataloader.dataset)\n",
        "    outputs_list = []\n",
        "\n",
        "    # Iterate over all batches. pbar:= allows us to display our training's progression with a progress bar.\n",
        "    for batch, (X, y) in (pbar:= tqdm(enumerate(dataloader), total=len(dataloader))):\n",
        "        # Need to convert X and y dtype to implement VGG16 later\n",
        "        X = X.to(device).float()\n",
        "        y = y.to(device).long()\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Add batch lostt to tensorboard's writer\n",
        "        writer.add_scalar(\"Loss/train\", loss, batch)\n",
        "\n",
        "        # Collect batch metrics in a list\n",
        "        outputs_list.append({\"loss\": loss, \"preds\": pred, \"labels\": y})\n",
        "\n",
        "        # Update progress bar\n",
        "        pbar.set_description(desc=f\"Train - Loss:{loss:.2f}\")\n",
        "\n",
        "    # Join batch metrics and compute accuracy\n",
        "    preds = torch.cat([x[\"preds\"] for x in outputs_list]).detach().cpu()\n",
        "    labels = torch.cat([x[\"labels\"] for x in outputs_list]).detach().cpu()\n",
        "    loss = torch.stack([x[\"loss\"] for x in outputs_list]).mean()\n",
        "    acc = metric(preds, labels)\n",
        "    \n",
        "    # Log everything to tensorboard's writer\n",
        "    writer.add_scalar(f\"train/loss\", loss, epoch)\n",
        "    writer.add_scalar(f\"train/acc\", acc, epoch)\n",
        "\n",
        "    print(f\"Train - Loss: {loss:.2f}, Acc: {acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "891DeX-QrAJx"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, metric, loss_fn, epoch, device):\n",
        "    outputs_list = []\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "\n",
        "    # We freeze the gradients at evaluation\n",
        "    with torch.no_grad():\n",
        "        for batch, (X, y) in (pbar:= tqdm(enumerate(dataloader), total=len(dataloader))):\n",
        "            X = X.to(device).float()\n",
        "            y = y.to(device).long()\n",
        "            pred = model(X)\n",
        "            test_loss = loss_fn(pred, y)\n",
        "            outputs_list.append({\"loss\": test_loss, \"preds\": pred, \"labels\": y})\n",
        "\n",
        "            pbar.set_description(desc=f\"Val - Loss:{test_loss:.2f}\")\n",
        "\n",
        "    preds = torch.cat([x[\"preds\"] for x in outputs_list]).detach().cpu()\n",
        "    labels = torch.cat([x[\"labels\"] for x in outputs_list]).detach().cpu()\n",
        "    loss = torch.stack([x[\"loss\"] for x in outputs_list]).mean()\n",
        "    acc = metric(preds, labels)\n",
        "    \n",
        "    writer.add_scalar(f\"val/loss\", loss, epoch)\n",
        "    writer.add_scalar(f\"val/acc\", acc, epoch)    \n",
        "\n",
        "    print(f\"Val - Loss: {loss:.2f}, Acc: {acc}\")\n",
        "    \n",
        "    # We return the accuracy to implement the Callback\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qF-YGmfarD_s"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "\n",
        "metric = MulticlassAccuracy(num_classes=10)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "model = LeNet().to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "epochs = 20\n",
        "best_acc = 0\n",
        "counter = 0\n",
        "patience = 5\n",
        "delta = 1e-4\n",
        "for t in range(epochs):\n",
        "    print(f\"-------------------------------\\nEpoch {t+1}\\n-------------------------------\")\n",
        "\n",
        "    model.train()\n",
        "    train(train_dataloader, model, metric, loss_fn, optimizer, t, device)\n",
        "    \n",
        "    model.eval()\n",
        "    val_acc = test(val_dataloader, model, metric, loss_fn, t, device)\n",
        "\n",
        "    # Callback: if the model does not improve significantly after some eopchs, stop training to prevent overfitting\n",
        "    if (val_acc > best_acc and val_acc-best_acc >= delta):\n",
        "        best_acc = val_acc\n",
        "        counter = 0\n",
        "    elif (val_acc > best_acc and val_acc-best_acc < delta):\n",
        "        best_acc = val_acc\n",
        "        counter += 1\n",
        "    else:\n",
        "        counter +=1\n",
        "\n",
        "    if counter >= patience:\n",
        "        print(f\"No significant improvement after {patience} epochs, stopping early.\")\n",
        "        break\n",
        "\n",
        "print(\"Done!\")\n",
        "writer.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "CaPi-Z3DrZfW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PS6aDuthV85A"
      },
      "outputs": [],
      "source": [
        "#Plot the curve of the metrics during training\n",
        "%tensorboard --logdir=runs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "model.eval()\n",
        "outputs_list = []\n",
        "with torch.no_grad():\n",
        "    for (X, y) in iter(test_dataloader):\n",
        "        X = X.to(device).float()\n",
        "        y = y.to(device).long()\n",
        "        pred = model(X)\n",
        "        outputs_list.append({\"preds\": pred, \"labels\": y})\n",
        "\n",
        "preds = torch.cat([x[\"preds\"] for x in outputs_list]).argmax(axis=1).detach().cpu()\n",
        "labels = torch.cat([x[\"labels\"] for x in outputs_list]).detach().cpu()\n",
        "\n",
        "acc = metric(preds, labels)\n",
        "\n",
        "print(\"Accuracy on test set: {0}\".format(acc))"
      ],
      "metadata": {
        "id": "PJCwx1U4ucsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jEoZxb2l--M"
      },
      "source": [
        "# II. Second step: Simple Convolutionnal Neural Network on more complex data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbGIVZForf3r"
      },
      "source": [
        "### Collecting and loading the data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to create a custom dataset that extends the Dataset class\n",
        "class MedMNISTDataset(Dataset):\n",
        "    def __init__(self, label_array, img_array, transform=None, target_transform=None):\n",
        "\n",
        "        # Load the npy arrays where our data is stored\n",
        "        self.img_labels = np.load(label_array)\n",
        "        self.img_array = np.load(img_array)\n",
        "\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        # Pair each image with its label and apply transformations\n",
        "        image = self.img_array[idx]\n",
        "        label = self.img_labels[idx, 0]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "gm1cJqtCqX80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ULAOQzgWtXi"
      },
      "outputs": [],
      "source": [
        "# preprocessing\n",
        "data_transform = Compose([\n",
        "    ToTensor(),\n",
        "])\n",
        "\n",
        "# load the data\n",
        "xTrain='/content/drive/MyDrive/Colab Notebooks/Computer Vision/Lab3/pathmnist/train_images.npy'\n",
        "xVal='/content/drive/MyDrive/Colab Notebooks/Computer Vision/Lab3/pathmnist/val_images.npy'\n",
        "xTest='/content/drive/MyDrive/Colab Notebooks/Computer Vision/Lab3/pathmnist/test_images.npy'\n",
        "\n",
        "yTrain='/content/drive/MyDrive/Colab Notebooks/Computer Vision/Lab3/pathmnist/train_labels.npy'\n",
        "yVal='/content/drive/MyDrive/Colab Notebooks/Computer Vision/Lab3/pathmnist/val_labels.npy'\n",
        "yTest='/content/drive/MyDrive/Colab Notebooks/Computer Vision/Lab3/pathmnist/test_labels.npy'\n",
        "\n",
        "\n",
        "# Wrap the data into datasets\n",
        "train_dataset = MedMNISTDataset(yTrain,xTrain, data_transform)\n",
        "val_dataset = MedMNISTDataset(yVal,xVal, data_transform)\n",
        "test_dataset = MedMNISTDataset(yTest,xTest, data_transform)\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "# Wrap datasets into dataloaders\n",
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring the data"
      ],
      "metadata": {
        "id": "OgvLa96ZrmMT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building and training the model"
      ],
      "metadata": {
        "id": "itQRJK-PrtMj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Architecture"
      ],
      "metadata": {
        "id": "FGz-vfFYrvzR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu-u-l_EUtA_"
      },
      "outputs": [],
      "source": [
        "class LeNetMed(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.conv_stack = nn.Sequential(\n",
        "            nn.Conv2d(3,6,(5,5),padding=2),\n",
        "            nn.Sigmoid(),\n",
        "            nn.AvgPool2d((2,2),stride=2),\n",
        "            nn.Conv2d(6,16,(5,5)),\n",
        "            nn.Sigmoid(),\n",
        "            nn.AvgPool2d((2,2),stride=2),\n",
        "        )\n",
        "        self.dense_stack = nn.Sequential(\n",
        "            nn.LazyLinear(120),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(120,84),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(84,9),\n",
        "            nn.Softmax()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_stack(x)\n",
        "        x = self.flatten(x)\n",
        "        logits = self.dense_stack(x)\n",
        "\n",
        "        return logits\n",
        "\n",
        "model_med = LeNetMed()\n",
        "print(model_med)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMrrzEQCS3CV"
      },
      "outputs": [],
      "source": [
        "batch = next(iter(train_dataloader))\n",
        "yhat = model_med(batch[0])\n",
        "\n",
        "make_dot(yhat, params=dict(list(model_med.named_parameters()))).render(\"model_med_torchviz\", format=\"png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "QeD-YJwWr0Bc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUlN501raXPT"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "\n",
        "metric = MulticlassAccuracy(num_classes=9)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "model_med = LeNetMed().to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model_med.parameters(), lr=learning_rate)\n",
        "epochs = 5\n",
        "best_acc = 0\n",
        "counter = 0\n",
        "patience = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model_med, metric, loss_fn, optimizer, t, device)\n",
        "    val_acc = test(val_dataloader, model_med, metric, loss_fn, t, device)\n",
        "    if (val_acc > best_acc and val_acc-best_acc >= 1e-4):\n",
        "        best_acc = val_acc\n",
        "        counter = 0\n",
        "    elif (val_acc > best_acc and val_acc-best_acc < 1e-4):\n",
        "        best_acc = val_acc\n",
        "        counter += 1\n",
        "    else:\n",
        "        counter +=1\n",
        "\n",
        "    if counter >= patience:\n",
        "        print(f\"No significant improvement after {patience} epochs, stopping early.\")\n",
        "        break\n",
        "print(\"Done!\")\n",
        "writer.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "2i2f0cy9r5Rg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbbIaupMaXPV"
      },
      "outputs": [],
      "source": [
        "#Plot the curve of the metrics during training\n",
        "%tensorboard --logdir=runs "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "outputs_list = []\n",
        "with torch.no_grad():\n",
        "    for (X, y) in iter(test_dataloader):\n",
        "        X = X.to(device).float()\n",
        "        y = y.to(device).long()\n",
        "        pred = model(X)\n",
        "        outputs_list.append({\"preds\": pred, \"labels\": y})\n",
        "\n",
        "preds = torch.cat([x[\"preds\"] for x in outputs_list]).argmax(axis=1).detach().cpu()\n",
        "labels = torch.cat([x[\"labels\"] for x in outputs_list]).detach().cpu()\n",
        "\n",
        "acc = metric(preds, labels)\n",
        "\n",
        "print(\"Accuracy on test set: {0}\".format(acc))"
      ],
      "metadata": {
        "id": "yoFzSETz1hey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzyPbiXU8m2Y"
      },
      "source": [
        "# III. Third step: Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import vgg16, VGG16_Weights\n",
        "weights=VGG16_Weights.DEFAULT\n",
        "preprocess = weights.transforms()\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import glob"
      ],
      "metadata": {
        "id": "39LR2dQhAkg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WxbuhZQsBZv"
      },
      "source": [
        "### Collecting and loading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gU_b3QQGZO58"
      },
      "outputs": [],
      "source": [
        "# WARNING: do not run this cell now. It is very time consuming. Run the next one and come back here if you have time later.\n",
        "datasetRoot='/content/drive/MyDrive/Colab Notebooks/Computer Vision/Lab3/animal-10/raw-img/'\n",
        "classes = ['mucca', 'elefante', 'gatto', 'cavallo', 'scoiattolo', 'ragno', 'pecora', 'farfalla', 'gallina', 'cane']\n",
        "nbClasses = len(classes)\n",
        "\n",
        "#training data\n",
        "\n",
        "rootTrain = datasetRoot+'train/'\n",
        "classLabel = 0\n",
        "\n",
        "xTrain = np.empty(shape=(0,224,224,3))\n",
        "yTrain = []\n",
        "first = True\n",
        "for cl in tqdm(classes):\n",
        "    listImages = glob.glob(rootTrain+cl+'/*')\n",
        "    yTrain += [classLabel]*100\n",
        "    for pathImg in tqdm(listImages[:100]):\n",
        "        img = Image.open(pathImg).resize((224, 224))\n",
        "        im = preprocess(img)\n",
        "        im = np.array(img)\n",
        "        im = np.expand_dims(im, axis=0)\n",
        "        xTrain = np.vstack([xTrain, im])\n",
        "    classLabel += 1\n",
        "print(len(yTrain))\n",
        "print(xTrain.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkVd3v4N3LnB"
      },
      "outputs": [],
      "source": [
        "# Load the training data\n",
        "\n",
        "datasetRoot='/content/drive/MyDrive/Colab Notebooks/Computer Vision/Lab3/animal-10/raw-img/'\n",
        "classes = ['mucca', 'gatto']\n",
        "nbClasses = len(classes)\n",
        "\n",
        "rootTrain = datasetRoot+'train/'\n",
        "classLabel = 0\n",
        "\n",
        "xTrain = np.empty(shape=(0,224,224,3))\n",
        "yTrain = []\n",
        "first = True\n",
        "for cl in tqdm(classes):\n",
        "    listImages = glob.glob(rootTrain+cl+'/*')\n",
        "    yTrain += [classLabel]*500\n",
        "    for pathImg in tqdm(listImages[:500]):\n",
        "        img = Image.open(pathImg).resize((224, 224))\n",
        "        im = preprocess(img)\n",
        "        im = np.array(img, dtype = \"float32\")\n",
        "        im = np.expand_dims(im, axis=0)\n",
        "        xTrain = np.vstack([xTrain, im])\n",
        "    classLabel += 1\n",
        "print(len(yTrain))\n",
        "print(xTrain.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zwi5TBlKajtt"
      },
      "outputs": [],
      "source": [
        "# Load the test data\n",
        "\n",
        "datasetRoot='/content/drive/MyDrive/Colab Notebooks/Computer Vision/Lab3/animal-10/raw-img/'\n",
        "\n",
        "rootTest = datasetRoot+'test/'\n",
        "classLabel = 0\n",
        "\n",
        "xTest = np.empty(shape=(0,224,224,3))\n",
        "yTest = []\n",
        "\n",
        "for cl in tqdm(classes):\n",
        "    listImages = glob.glob(rootTest+cl+'/*')\n",
        "    yTest += [classLabel]*len(listImages)\n",
        "    for pathImg in tqdm(listImages):\n",
        "        img = Image.open(pathImg).resize((224, 224))\n",
        "        im = preprocess(img)\n",
        "        im = np.array(img, dtype = \"float32\")\n",
        "        im = np.expand_dims(im, axis=0)\n",
        "        xTest = np.vstack([xTest, im])\n",
        "    classLabel += 1\n",
        "print(len(yTest))\n",
        "print(xTest.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AnimalDataset(Dataset):\n",
        "    def __init__(self, label_array, img_array):\n",
        "        self.img_labels = label_array\n",
        "        self.img_array = img_array\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = torch.tensor(self.img_array[idx].transpose(2, 0, 1), dtype = torch.float)\n",
        "        label = torch.tensor(self.img_labels[idx], dtype = torch.float)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "p8iVfMt2VMsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_val_dataset = AnimalDataset(yTrain,xTrain)\n",
        "test_dataset = AnimalDataset(yTest, xTest)\n",
        "\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_val_dataset, [0.8, 0.2])\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "2p9jVaGRWAcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring the data"
      ],
      "metadata": {
        "id": "oeaPQjDgsF9F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjG0Ra1bNPnW"
      },
      "outputs": [],
      "source": [
        "#Let's plot an image\n",
        "\n",
        "plt.imshow((xTrain[100] * 255).astype(np.uint8))\n",
        "print(yTrain[100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og1KZntwavZT"
      },
      "source": [
        "## Pre-trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Architecture"
      ],
      "metadata": {
        "id": "X-BevdBesmAi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofrQr-x_a-Bi"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained VGG16 model\n",
        "vgg16_model = vgg16(weights = VGG16_Weights.DEFAULT)\n",
        "\n",
        "# Customize pooling and classifier layers of the model\n",
        "vgg16_model.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "\n",
        "vgg16_model.classifier = nn.Sequential(\n",
        "    nn.Linear(in_features=512, out_features=1024, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(in_features=1024, out_features=2, bias=True),\n",
        "    nn.Softmax(),\n",
        "  )\n",
        "\n",
        "# Freeze all layers except for the classifier's\n",
        "for child in list(vgg16_model.children())[:-1]:\n",
        "    for param in list(child.parameters()):\n",
        "        param.requires_grad = False\n",
        "\n",
        "vgg16_classifier_model = vgg16_model\n",
        "\n",
        "print(vgg16_classifier_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(vgg16_classifier_model.to(device), (3,224,224))"
      ],
      "metadata": {
        "id": "tiDiMWkCd5tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PuXNGD-KUvl"
      },
      "outputs": [],
      "source": [
        "## Let us plot the model's graph and each layer's shapes\n",
        "batch = list(train_dataloader)[0]\n",
        "yhat = vgg16_classifier_model(batch[0].to(device))\n",
        "\n",
        "make_dot(yhat, params=dict(list(vgg16_classifier_model.named_parameters()))).render(\"model_animal_torchviz\", format=\"png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "gahlXWIIsq-C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrLUhA2-b8Fv"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-2\n",
        "\n",
        "metric = MulticlassAccuracy(num_classes=2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "model = vgg16_classifier_model.to(device)\n",
        "\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "epochs = 20\n",
        "best_acc = 0\n",
        "counter = 0\n",
        "patience = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "\n",
        "    model.train()\n",
        "    train(train_dataloader, model, metric, loss_fn, optimizer, t, device)\n",
        "\n",
        "    model.eval()\n",
        "    val_acc = test(val_dataloader, model, metric, loss_fn, t, device)\n",
        "    if (val_acc > best_acc and val_acc-best_acc >= 1e-4):\n",
        "        best_acc = val_acc\n",
        "        counter = 0\n",
        "    elif (val_acc > best_acc and val_acc-best_acc < 1e-4):\n",
        "        best_acc = val_acc\n",
        "        counter += 1\n",
        "    else:\n",
        "        counter +=1\n",
        "\n",
        "    if counter >= patience and best_acc >= val_acc:\n",
        "        print(f\"No significant improvement after {patience} epochs, stopping early.\")\n",
        "        break\n",
        "print(\"Done!\")\n",
        "writer.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hgDguiNcNXZ"
      },
      "source": [
        "## Fine-tune the network"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us check all the named parameters in the model\n",
        "i=0\n",
        "for name, param in model.features.named_parameters():\n",
        "    i+=1\n",
        "    print(i,name)"
      ],
      "metadata": {
        "id": "VCLOyPNx_Y43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C17ts6kllGUr"
      },
      "outputs": [],
      "source": [
        "# Unfreeze all layers starting from the last convolutional layer\n",
        "\n",
        "for param in list(vgg16_classifier_model.features.named_parameters())[-2:]:\n",
        "    param[1].requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We use a smaller learning rate to fine-tune the model\n",
        "learning_rate = 1e-4\n",
        "\n",
        "metric = MulticlassAccuracy(num_classes=2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "model = vgg16_classifier_model.to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "epochs = 20\n",
        "best_acc = 0\n",
        "counter = 0\n",
        "patience = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "\n",
        "    model.train()\n",
        "    train(train_dataloader, model, metric, loss_fn, optimizer, t, device)\n",
        "\n",
        "    model.eval()\n",
        "    val_acc = test(test_dataloader, model, metric, loss_fn, t, device)\n",
        "    if (val_acc > best_acc and val_acc-best_acc >= 1e-4):\n",
        "        best_acc = val_acc\n",
        "        counter = 0\n",
        "    elif (val_acc > best_acc and val_acc-best_acc < 1e-4):\n",
        "        best_acc = val_acc\n",
        "        counter += 1\n",
        "    else:\n",
        "        counter +=1\n",
        "\n",
        "    if counter >= patience and best_acc >= val_acc:\n",
        "        print(f\"No significant improvement after {patience} epochs, stopping early.\")\n",
        "        break\n",
        "print(\"Done!\")\n",
        "writer.flush()"
      ],
      "metadata": {
        "id": "TfSCzVFRAnQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "NXc18CVCszzd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNI7pEEo0B5F"
      },
      "outputs": [],
      "source": [
        "# Plot the curves of the metrics\n",
        "%tensorboard --logdir=runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L30MfqXQx46l"
      },
      "outputs": [],
      "source": [
        "# Let us compute the confusion matrix\n",
        "outputs_list = []\n",
        "with torch.no_grad():\n",
        "    for (X, y) in list(test_dataloader):\n",
        "        X = X.to(device).float()\n",
        "        y = y.to(device).long()\n",
        "        pred = model(X)\n",
        "        test_loss = loss_fn(pred, y)\n",
        "        # correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "        outputs_list.append({\"preds\": pred})\n",
        "\n",
        "preds = torch.cat([x[\"preds\"] for x in outputs_list]).detach().cpu()\n",
        "\n",
        "y_classes = preds.argmax(axis=-1)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_true = yTest, y_pred = y_classes)\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhQPI1EVyp-W"
      },
      "outputs": [],
      "source": [
        "# Nicer Display:\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df_cm = pd.DataFrame(cm)\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm, annot=True)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
